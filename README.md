# MLOps Platform

> `Men's CLUB` `ë¨¸ì‹ ëŸ¬ë‹/ì›¹` ìš´ì˜ì„ ìœ„í•œ ì˜¤í¼ë ˆì´ì…˜ ì €ì¥ì†Œ 

## Architecture Overview

ì´ í”„ë¡œì íŠ¸ëŠ” Docker Composeë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì˜ MLOps í”Œë«í¼ì…ë‹ˆë‹¤.

### Core Services

| Service | Description | Port | 
|---------|-------------|------|
| **Airflow** | ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ | 8080 |
| **Database** | MySQL/PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ | 3306/5432 |
| **MLflow** | ML ëª¨ë¸ ê´€ë¦¬ ë° ì‹¤í—˜ ì¶”ì  | 5000 |
| **Monitoring** | Prometheus + Grafana | 9090, 3000 |
| **Logging** | ELK Stack (Elasticsearch, Logstash, Kibana) | 9200, 5601 |

### Proxy Services

- **database.proxy**: Elasticsearch í”„ë¡ì‹œ
- **model.proxy**: ëª¨ë¸ ì„œë¹™ API í”„ë¡ì‹œ  
- **monitoring.proxy**: ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ í”„ë¡ì‹œ

## Project Structure

```bash 
project_root/
â”œâ”€â”€ airflow/                     
#  ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â”œâ”€â”€ dags/                   
# Airflow DAG ì •ì˜
â”‚   â”‚   â”œâ”€â”€ evaluation.py       
# ëª¨ë¸ í‰ê°€ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ fill_data.py        
# ë°ì´í„° ì ì¬ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â”œâ”€â”€ train.py            
# ëª¨ë¸ í›ˆë ¨ íŒŒì´í”„ë¼ì¸
â”‚   â”‚   â””â”€â”€ config/             
# ì„¤ì • ë° ìœ í‹¸ë¦¬í‹°
â”‚   â””â”€â”€ module/                 
# ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ëª¨ë“ˆ
â”‚       â”œâ”€â”€ database_fill_chain.py
â”‚       â”œâ”€â”€ train_piepeline.py
â”‚       â””â”€â”€ validating_model.py
â”œâ”€â”€ database/                   
#  ë°ì´í„°ë² ì´ìŠ¤ ì„œë¹„ìŠ¤
â”œâ”€â”€ database.proxy/             
#  Elasticsearch í”„ë¡ì‹œ
â”œâ”€â”€ logging/                    
#  ë¡œê¹… ìŠ¤íƒ (ELK)
â”‚   â”œâ”€â”€ kibana/
â”‚   â””â”€â”€ logstash/
â”œâ”€â”€ mlflow/                     
#  ML ì‹¤í—˜ ê´€ë¦¬
â”œâ”€â”€ model.proxy/                
#  ëª¨ë¸ ì„œë¹™ í”„ë¡ì‹œ
â”œâ”€â”€ monitoring/                 
#  ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ
â”‚   â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ prometheus/
â””â”€â”€ monitoring.proxy/           
# ëª¨ë‹ˆí„°ë§ í”„ë¡ì‹œ
```

## Quick Start

### Prerequisites

- Docker & Docker Compose
- Git

### 1. Clone Repository

```bash
git clone https://github.com/Mens-Club/Operation.git
cd Operation
```

### 2. Environment Setup

ê° ì„œë¹„ìŠ¤ ë””ë ‰í† ë¦¬ì˜ `.env` íŒŒì¼ì„ ì„¤ì •í•˜ì„¸ìš”:

```bash
# Copy example environment files
cp airflow/.env.example airflow/.env
cp database/.env.example database/.env
cp monitoring/.env.example monitoring/.env
# ... other services
```

### 3. Start Services

```bash
# Start all services
docker-compose -f database/mensclub.main.docker-compose.yaml up -d
docker-compose -f airflow/airflow.docker-compose.yaml up -d
docker-compose -f monitoring/monitoring.docker-compose.yaml up -d
docker-compose -f logging/logging.docker-compose.yaml up -d
docker-compose -f mlflow/validation.docker-compose.yaml up -d

# Or use the startup script
./scripts/start-all.sh
```

### 4. Access Services

| Service | URL | Credentials |
|---------|-----|-------------|
| Airflow | http://localhost:8080 | admin/admin |
| MLflow | http://localhost:5000 | - |
| Grafana | http://localhost:3000 | admin/admin |
| Kibana | http://localhost:5601 | - |

## ğŸ“‹ Data Pipelines

### Airflow DAGs

1. **fill_data.py**: ë°ì´í„° ìˆ˜ì§‘ ë° ì ì¬
   - ì™¸ë¶€ ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘
   - ë°ì´í„° ê²€ì¦ ë° ì „ì²˜ë¦¬
   - ë°ì´í„°ë² ì´ìŠ¤ ì ì¬

2. **train.py**: ëª¨ë¸ í›ˆë ¨ íŒŒì´í”„ë¼ì¸
   - í›ˆë ¨ ë°ì´í„° ì¤€ë¹„
   - ëª¨ë¸ í›ˆë ¨ ì‹¤í–‰
   - MLflowì— ëª¨ë¸ ë“±ë¡

3. **evaluation.py**: ëª¨ë¸ í‰ê°€ íŒŒì´í”„ë¼ì¸
   - ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
   - A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„
   - ëª¨ë¸ ìŠ¹ê²©/ë°°í¬ ê²°ì •

### Pipeline Schedule

- **Data Fill**: Daily at 2:00 AM
- **Model Training**: Weekly (Monday 3:00 AM)
- **Model Evaluation**: Daily at 6:00 AM

## ğŸ”§ Configuration

### Database Configuration

```python
# airflow/dags/config/connection.py
DATABASE_CONFIG = {
    'host': 'database',
    'port': 3306,
    'database': 'mlops',
    'user': 'admin',
    'password': 'password'
}
```

### Model Training Configuration

```python
# airflow/dags/config/train_utils.py
TRAINING_CONFIG = {
    'batch_size': 32,
    'epochs': 100,
    'learning_rate': 0.001,
    'model_type': 'transformer'
}
```

## Monitoring & Logging

### Prometheus Metrics

- Airflow task success/failure rates
- Model performance metrics
- System resource usage
- Database connection status

### Grafana Dashboards

- **ML Pipeline Dashboard**: DAG ì‹¤í–‰ ìƒíƒœ ëª¨ë‹ˆí„°ë§
- **Model Performance Dashboard**: ëª¨ë¸ ì„±ëŠ¥ ì¶”ì 
- **System Health Dashboard**: ì¸í”„ë¼ ìƒíƒœ ëª¨ë‹ˆí„°ë§

### ELK Stack

- **Elasticsearch**: ë¡œê·¸ ì €ì¥ì†Œ
- **Logstash**: ë¡œê·¸ ìˆ˜ì§‘ ë° ì²˜ë¦¬
- **Kibana**: ë¡œê·¸ ì‹œê°í™” ë° ë¶„ì„

## ğŸ” Development

### Local Development

```bash
# Start local Airflow for development
docker-compose -f airflow/local.airflow.docker-compose.yaml up -d

# Access Airflow locally
http://localhost:8080
```

### Adding New DAGs

1. `airflow/dags/` ë””ë ‰í† ë¦¬ì— ìƒˆ DAG íŒŒì¼ ìƒì„±
2. í•„ìš”í•œ ì„¤ì •ì„ `airflow/dags/config/`ì— ì¶”ê°€
3. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ì„ `airflow/module/`ì— êµ¬í˜„


### Monitoring API

# Get metrics
curl http://localhost:9090/api/v1/query?query=up

## ğŸ·ï¸ Tags

`mlops` `airflow` `docker` `machine-learning` `data-pipeline` `monitoring` `elasticsearch` `grafana` `prometheus` `mlflow`